{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Performance Investigation of Hybrid Life-Cycle Assessment Matrix Calculations\n",
    "\n",
    "This notebook is available online in this Zenodo Record: [`doi:10.5281/zenodo.14786979`](https://doi.org/10.5281/zenodo.14786979)\n",
    "\n",
    "Note that this investigation was originally run in January 2025 run using a virutal environment with the following packages:\n",
    "\n",
    "```\n",
    "numpy==2.2.1\n",
    "scipy==1.15.0\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scientific computing\n",
    "import numpy as np\n",
    "rng = np.random.default_rng(seed=42)\n",
    "import pandas as pd\n",
    "# data storage\n",
    "import gzip\n",
    "import pickle\n",
    "# system libraries\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The below code simply implements the governing equation of environmentally extended input-output analysis:\n",
    "\n",
    "\\begin{align}\n",
    "e &= \\mathbf{C} \\cdot \\mathbf{B} \\cdot (\\mathbf{I} - \\mathbf{A})^{-1} \\cdot \\vec{f} \\\\\n",
    "[1 \\times 1] &= [1 \\times N] \\cdot [N \\times N] \\cdot [N \\times 1]\n",
    "\\end{align}\n",
    "\n",
    "| Symbol | Dimension | Units | Description |\n",
    "| ------ | --------- | ----- | ----------- |\n",
    "| $e$ | $1 \\times 1$ | kg(CO₂ eq.) |  environmental impact (scalar) |\n",
    "| $\\mathbf{C}$ | $N \\times N$ | AUD |  total requirements matrix |\n",
    "| $\\mathbf{B}$ | $1 \\times N$ | kg(CO₂ eq.)/AUD |  environmental satellite account |\n",
    "| $\\mathbf{I}$ | $N \\times N$ | None |  identity matrix |\n",
    "| $\\mathbf{A}$ | $N \\times N$ | AUD/AUD=None|  technical coefficient matrix |\n",
    "| $\\vec{f}$ | $N \\times 1$ | AUD | final demand vector |\n",
    "\n",
    "Here, $N$ is the number of sectors in the economy.\n",
    "\n",
    "For further reference, compare [Miller & Blair (2022)](https://doi.org/10.1017/9781108676212), Eq. (2.11) and Section 13.7.1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Compressed Data from `pylcaio` Package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/9l/8ctsrnn52fgbfv9t_tv0spfc0000gn/T/ipykernel_2286/2026521812.py:3: DeprecationWarning: Please import `csr_matrix` from the `scipy.sparse` namespace; the `scipy.sparse.csr` namespace is deprecated and will be removed in SciPy 2.0.0.\n",
      "  picklefile = pickle.load(file=pickle_file)\n"
     ]
    }
   ],
   "source": [
    "path = '/Users/michaelweinold/Library/CloudStorage/OneDrive-TheWeinoldFamily/Documents/University/PhD/Data/HLCA Matrices/hybrid_system.pickle'\n",
    "with gzip.open(path, 'rb') as pickle_file:\n",
    "    picklefile = pickle.load(file=pickle_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Hybrid Matrices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the definition of the matrices in the output of the [`pylcaio` package](https://github.com/MaximeAgez/pylcaio/tree/master), see [this section of the source code](https://github.com/MaximeAgez/pylcaio/blob/505898a39144ebc53c109e485644e3ea055ae0ae/src/pylcaio.py#L46\n",
    "). The matrices are defined as follows:\n",
    "\n",
    "| Symbol | Dimension | Units | Description |\n",
    "| ------ | --------- | ----- | ----------- |\n",
    "| $\\mathbf{A}_P$ | $M \\times M$ | [kg] (\"physical\") | technosphere matrix |\n",
    "| $\\mathbf{A}_S$ | $N \\times N$ | [\\$] (\"monetary\") | technical coefficient matrix |\n",
    "| $\\mathbf{C}_U$ | $N \\times N$ | None |  upstream cut-off matrix |\n",
    "| $\\mathbf{B}_P$ | $R \\times R$ | XXX | biosphere matrix |\n",
    "| $\\mathbf{B}_S$ | $P \\times P$ | XXX | environmental satellite matrix |\n",
    "| $\\mathbf{C}_P$ | $ \\times $ | XXX | characterization matrix process system |\n",
    "| $\\mathbf{C}_S$ | $ \\times $ | XXX | characterization matrix sectoral system |\n",
    "\n",
    "The hybrid matrices are build such that:\n",
    "\n",
    "\\begin{align}\n",
    "\\mathbf{A}_H &= \\begin{bmatrix}\n",
    "\\mathbf{A}_P & \\mathbf{0} \\\\\n",
    "\\mathbf{C}_U & \\mathbf{A}_S\n",
    "\\end{bmatrix} \\\\\n",
    "\\mathbf{A}_H &= [(M+N) \\times (M+N)]\n",
    "\\end{align}\n",
    "\n",
    "and\n",
    "\n",
    "\\begin{align}\n",
    "\\mathbf{B}_H = \\begin{bmatrix}\n",
    "\\mathbf{B}_P & \\mathbf{B}_S\n",
    "\\end{bmatrix} \\\\\n",
    "\\mathbf{B}_H = [(R+P) \\times 1]\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "A_P = picklefile['A_ff'].todense().A\n",
    "A_S = picklefile['A_io'].todense().A\n",
    "C_U = picklefile['A_io_f'].todense().A\n",
    "A_H = np.block(\n",
    "    [\n",
    "        [np.eye(A_P.shape[0]) - A_P, np.zeros((A_P.shape[0], A_S.shape[0]))],\n",
    "        [C_U, np.eye(A_S.shape[0]) - A_S]\n",
    "    ]\n",
    ")\n",
    "\n",
    "B_S = picklefile['F_io'].todense().A\n",
    "B_P = picklefile['F_f'].todense().A\n",
    "B_H = np.block(\n",
    "    [\n",
    "        [B_P, np.zeros((B_P.shape[0], B_S.shape[1]))],\n",
    "        [np.zeros((B_S.shape[0], B_P.shape[1])), B_S]\n",
    "    ]\n",
    ")\n",
    "\n",
    "C_P_climate = picklefile['C_f'].todense().A[0,:]\n",
    "C_S_climate = picklefile['C_io'].todense().A[0,:]\n",
    "C_H_climate = np.concatenate((C_P_climate, C_S_climate), axis=0).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Random Sample of Ecoinvent Processes\n",
    "\n",
    "Every Ecoinvent process has an industry classification code according to the International Standard Industrial Classification of All Economic Activities (ISIC). We use the highest-level classification structure of the 21 (A-U) ISIC \"sections\" to group Ecoinvent processes (see [\"Classification Structure\"](https://unstats.un.org/unsd/classifications/Family/Detail/27))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_isic_letters_and_numbers = {\n",
    "    'A': ['01', '02', '03'],\n",
    "    'B': ['05', '06', '07', '08', '09'],\n",
    "    'C': [\n",
    "        '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20', \n",
    "        '21', '22', '23', '24', '25', '26', '27', '28', '29', '30', \n",
    "        '31', '32', '33'\n",
    "    ],\n",
    "    'D': ['35'],\n",
    "    'E': ['36', '37', '38', '39'],\n",
    "    'F': ['41', '42', '43'],\n",
    "    'G': ['45', '46', '47'],\n",
    "    'H': ['49', '50', '51', '52', '53'],\n",
    "    'I': ['55', '56'],\n",
    "    'J': ['58', '59', '60', '61', '62', '63'],\n",
    "    'K': ['64', '65', '66'],\n",
    "    'L': ['68'],\n",
    "    'M': ['69', '70', '71', '72', '73', '74', '75'],\n",
    "    'N': ['77', '78', '79', '80', '81', '82'],\n",
    "    'O': ['84'],\n",
    "    'P': ['85'],\n",
    "    'Q': ['86', '87', '88'],\n",
    "    'R': ['90', '91', '92', '93'],\n",
    "    'S': ['94', '95', '96'],\n",
    "    'T': ['97', '98'],\n",
    "    'U': ['99']\n",
    "}\n",
    "list_process_metadata_isic = [i for i in picklefile['PRO_f']['ISIC'].values()]\n",
    "list_process_metadata_isic_numbers = [str(string)[:2] for string in list_process_metadata_isic]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sample_process_indices_from_ecoinvent_per_isic_letter(\n",
    "    dict_isic_letters_and_numbers: dict,\n",
    "    list_process_metadata_isic_numbers: list,\n",
    "    number_of_indices_per_isic_letter: int,\n",
    ") -> dict:\n",
    "    \"\"\"\n",
    "    Gets a random sample of process indices from the ecoinvent database for each ISIC letter (=sections).\n",
    "\n",
    "    If the number of processes for a given ISIC letter is less than the number of indices to be sampled,\n",
    "    the function will sample all available processes.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    dict_isic_letters_and_numbers : dict\n",
    "        Dictionary with ISIC letters (=sections) as keys and lists of ISIC numbers (=divisions) as values.\n",
    "        For example: {'A': ['01', '02', '03'], 'B': ['05', '06', '07', '08', '09'], ...}\n",
    "    list_process_metadata_isic_numbers : list\n",
    "        List of ISIC numbers for each process in the ecoinvent database.\n",
    "        For example: ['01', '01', '02', '02', '02', '03', ...]\n",
    "    number_of_indices_per_isic_letter : int\n",
    "        Number of indices to be sampled for each ISIC letter.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    dict\n",
    "        Dictionary with ISIC letters as keys and lists of sampled process indices as values.\n",
    "        For example: {'A': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9], 'B': [10, 11, 12, 13, 14, 15, 16, 17, 18, 19], ...}\n",
    "    \"\"\"\n",
    "    \n",
    "    dict_isic_letters_and_indices = {}\n",
    "\n",
    "    for isic_letter in dict_isic_letters_and_numbers.keys():\n",
    "        list_of_process_indices = []\n",
    "        for isic_number in dict_isic_letters_and_numbers[isic_letter]:\n",
    "            list_of_process_indices += [index for index, element in enumerate(list_process_metadata_isic_numbers) if element == isic_number]\n",
    "        dict_isic_letters_and_indices[isic_letter] = list_of_process_indices\n",
    "\n",
    "    dict_return = {}\n",
    "\n",
    "    for isic_letter, isic_numbers in dict_isic_letters_and_indices.items():\n",
    "        sample_size = number_of_indices_per_isic_letter\n",
    "        if dict_isic_letters_and_indices[isic_letter] == []:\n",
    "            continue\n",
    "        if len(isic_numbers) < number_of_indices_per_isic_letter:\n",
    "            sample_size = len(isic_numbers)\n",
    "        dict_return[isic_letter] = rng.choice(\n",
    "            a=dict_isic_letters_and_indices[isic_letter],\n",
    "            size=sample_size,\n",
    "            replace=False\n",
    "        ).tolist()\n",
    "        \n",
    "    return dict_return\n",
    "\n",
    "dict_sample_process_indices = get_sample_process_indices_from_ecoinvent_per_isic_letter(\n",
    "    dict_isic_letters_and_numbers=dict_isic_letters_and_numbers,\n",
    "    list_process_metadata_isic_numbers=list_process_metadata_isic_numbers,\n",
    "    number_of_indices_per_isic_letter=10\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_final_demand_vector(\n",
    "    number_of_sectors: int,\n",
    "    sector_index: int,\n",
    "    demand_amount: float\n",
    ") -> np.ndarray:\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    _extended_summary_\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    number_of_sectors : int\n",
    "        _description_\n",
    "    sector_index : int\n",
    "        _description_\n",
    "    demand_amount : float\n",
    "        _description_\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    np.ndarray\n",
    "        _description_\n",
    "    \"\"\"\n",
    "    f_vector = np.zeros(number_of_sectors)\n",
    "    f_vector[sector_index] = demand_amount\n",
    "    return f_vector\n",
    "\n",
    "\n",
    "def compute_environmental_burden(\n",
    "    A_H: np.ndarray,\n",
    "    B_H: np.ndarray,\n",
    "    C_H_climate: np.ndarray,\n",
    "    sector_index: int,\n",
    ") -> tuple[float, float]:\n",
    "    \"\"\"_summary_\n",
    "\n",
    "    _extended_summary_\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    A_H : np.ndarray\n",
    "        _description_\n",
    "    B_H : np.ndarray\n",
    "        _description_\n",
    "    C_H_climate : np.ndarray\n",
    "        _description_\n",
    "    sector_index : int\n",
    "        _description_\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    tuple[float, float]\n",
    "        _description_\n",
    "    \"\"\"\n",
    "    f_vector_H = generate_final_demand_vector(\n",
    "        number_of_sectors=A_H.shape[0],\n",
    "        sector_index=sector_index,\n",
    "        demand_amount=1\n",
    "    )\n",
    "    start = time.time()\n",
    "    vec_intermediate_demand = np.linalg.solve(A_H, f_vector_H)\n",
    "    vec_environmental_flows = np.dot(B_H, vec_intermediate_demand)\n",
    "    scal_environmental_burden = np.dot(C_H_climate, vec_environmental_flows)\n",
    "    end = time.time()\n",
    "    computation_time = end - start\n",
    "    return scal_environmental_burden, computation_time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before starting calculations, ensure that your local NumPy is built against a fast [BLAS library](https://en.wikipedia.org/wiki/Basic_Linear_Algebra_Subprograms) (e.g., Intel MKL, OpenBLAS, or Apple Accelerate).\n",
    "\n",
    "Note that on a 2021 MacBook Pro (M1 Max CPU) with NumPy v2.2.1 [built against Apple Accelerate](https://numpy.org/doc/2.0/release/1.21.0-notes.html#enable-accelerate-framework), one computation takes approximately 130-190 seconds."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "numscipy",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
